{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./tos.csv\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(\"Unnamed: 0\", axis=1)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>score</th>\n",
              "      <th>class</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>signal does not sell, rent or monetize your pe...</td>\n",
              "      <td>25</td>\n",
              "      <td>good</td>\n",
              "      <td>signal.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you must be at least 13 years old to use our s...</td>\n",
              "      <td>15</td>\n",
              "      <td>neutral</td>\n",
              "      <td>signal.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you agree to resolve any claim you have with u...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>signal.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we may modify, suspend, or terminate your acce...</td>\n",
              "      <td>60</td>\n",
              "      <td>bad</td>\n",
              "      <td>signal.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we work with third parties to provide some of ...</td>\n",
              "      <td>15</td>\n",
              "      <td>bad</td>\n",
              "      <td>signal.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  score    class  \\\n",
              "0  signal does not sell, rent or monetize your pe...     25     good   \n",
              "1  you must be at least 13 years old to use our s...     15  neutral   \n",
              "2  you agree to resolve any claim you have with u...      0  neutral   \n",
              "3  we may modify, suspend, or terminate your acce...     60      bad   \n",
              "4  we work with third parties to provide some of ...     15      bad   \n",
              "\n",
              "      filename  \n",
              "0  signal.json  \n",
              "1  signal.json  \n",
              "2  signal.json  \n",
              "3  signal.json  \n",
              "4  signal.json  "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import string"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(420)\n",
        "torch.cuda.is_available()\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_tokens(text):\n",
        "    if isinstance(text, str):\n",
        "#         print(f\"======={text}\")\n",
        "        text = text.split()\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        tokens = [w.translate(table) for w in text]\n",
        "        \n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return None"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokens'] = df['data'].apply(prepare_tokens)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>score</th>\n",
              "      <th>class</th>\n",
              "      <th>filename</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>signal does not sell, rent or monetize your pe...</td>\n",
              "      <td>25</td>\n",
              "      <td>good</td>\n",
              "      <td>signal.json</td>\n",
              "      <td>signal does not sell rent or monetize your per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you must be at least 13 years old to use our s...</td>\n",
              "      <td>15</td>\n",
              "      <td>neutral</td>\n",
              "      <td>signal.json</td>\n",
              "      <td>you must be at least 13 years old to use our s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you agree to resolve any claim you have with u...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>signal.json</td>\n",
              "      <td>you agree to resolve any claim you have with u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we may modify, suspend, or terminate your acce...</td>\n",
              "      <td>60</td>\n",
              "      <td>bad</td>\n",
              "      <td>signal.json</td>\n",
              "      <td>we may modify suspend or terminate your access...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we work with third parties to provide some of ...</td>\n",
              "      <td>15</td>\n",
              "      <td>bad</td>\n",
              "      <td>signal.json</td>\n",
              "      <td>we work with third parties to provide some of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  score    class  \\\n",
              "0  signal does not sell, rent or monetize your pe...     25     good   \n",
              "1  you must be at least 13 years old to use our s...     15  neutral   \n",
              "2  you agree to resolve any claim you have with u...      0  neutral   \n",
              "3  we may modify, suspend, or terminate your acce...     60      bad   \n",
              "4  we work with third parties to provide some of ...     15      bad   \n",
              "\n",
              "      filename                                             tokens  \n",
              "0  signal.json  signal does not sell rent or monetize your per...  \n",
              "1  signal.json  you must be at least 13 years old to use our s...  \n",
              "2  signal.json  you agree to resolve any claim you have with u...  \n",
              "3  signal.json  we may modify suspend or terminate your access...  \n",
              "4  signal.json  we work with third parties to provide some of ...  "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "df['class_id'] = 0\n",
        "df.loc[df[\"class\"]==\"neutral\", \"class_id\"] = 1\n",
        "df.loc[df[\"class\"]==\"good\", \"class_id\"] = 2\n",
        "df.loc[df[\"class\"]==\"blocker\", \"class_id\"] = 3"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.class_id.hist()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffac29f8240>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": [
              "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\n"
            ],
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[df.class_id != 3]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": [
              "(2397, 6)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "word_to_ix = {'PAD': 0}\n",
        "for sent in df.tokens.tolist():\n",
        "    if sent:\n",
        "#         print(sent)\n",
        "        for word in sent.split():\n",
        "            if word not in word_to_ix:\n",
        "                word_to_ix[word] = len(word_to_ix)\n",
        "# print(word_to_ix)\n",
        "tag_to_ix = {\"bad\": 0, \"neutral\": 1, \"good\": 2, \"blocker\": 3}"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_to_ix)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": [
              "6250"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "BATCH_SIZE = 16"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class TOSClaasifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size, batch_size):\n",
        "        super(TOSClaasifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.target_size = target_size\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.LSTM = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=0.3, num_layers=2)\n",
        "        \n",
        "        self.h1 = nn.Linear(hidden_dim*150, 512)\n",
        "        self.hidden2tag = nn.Linear(512, target_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.embed_dim = embedding_dim\n",
        "        \n",
        "\n",
        "    def forward(self, sentence):\n",
        "#         print(sentence.shape)\n",
        "        embeds = self.word_embeddings(sentence.view(self.batch_size,-1))\n",
        "#         print(embeds.shape)\n",
        "        lstm_out, _ = self.LSTM(embeds.view(self.batch_size, 150, self.embed_dim))\n",
        "#         print(lstm_out.shape)\n",
        "        lstm_out = lstm_out.contiguous().view(self.batch_size,-1)\n",
        "#         print(lstm_out.shape)\n",
        "        tag_space = self.h1(lstm_out)\n",
        "#         print(tag_space.shape)\n",
        "\n",
        "        tag_space = self.hidden2tag(tag_space)\n",
        "#         print(tag_space.shape)\n",
        "        \n",
        "#         tag_score = F.log_softmax(tag_space.view(self.batch_size, -1, self.target_size))\n",
        "        tag_score = F.log_softmax(tag_space, dim=0)\n",
        "        tag_score = tag_score.view(self.batch_size, self.target_size)\n",
        "#         print(tag_score)\n",
        "#         tag_score = tag_score[:, -1] # get last batch of labels\n",
        "        return tag_score\n",
        "        "
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = TOSClaasifier(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), 3, BATCH_SIZE)\n",
        "model = model.cuda()\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.NLLLoss().cuda()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "# optimizer = optim.RMSprop(model.parameters())\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq.split()]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOSClaasifier(\n",
            "  (word_embeddings): Embedding(6250, 128)\n",
            "  (LSTM): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
            "  (h1): Linear(in_features=38400, out_features=512, bias=True)\n",
            "  (hidden2tag): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[~df.tokens.isna()]"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
        "    \n",
        "    for i, review in enumerate(reviews_int):\n",
        "        review_len = len(review)\n",
        "        \n",
        "        if review_len <= seq_length:\n",
        "            zeroes = np.zeros(seq_length-review_len).astype(np.int)\n",
        "#             print(zeroes)\n",
        "#             print(review.numpy())\n",
        "            new = np.concatenate((review.numpy(),zeroes), axis=None)\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "        \n",
        "        features[i,:] = np.array(new)\n",
        "    \n",
        "    return features"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "seq_ids = df.tokens.apply(prepare_sequence, args=[word_to_ix]).tolist()\n",
        "label_ids = df['class'].apply(prepare_sequence, args=[tag_to_ix]).tolist()"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "feats = pad_features(seq_ids, 150)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "label_ids"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "feats"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": [
              "array([[   1,    2,    3, ...,    0,    0,    0],\n",
              "       [  17,   18,   19, ...,    0,    0,    0],\n",
              "       [  17,   39,   25, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  87,  185,    3, ...,    0,    0,    0],\n",
              "       [ 122, 2832,   25, ...,    0,    0,    0],\n",
              "       [  87,  158,   17, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=420)\n",
        "for train, test in sss.split(feats, label_ids):\n",
        "    train_X = feats[train]\n",
        "    train_y = np.array(label_ids)[train]\n",
        "    \n",
        "    test_X = feats[test]\n",
        "    test_y = np.array(label_ids)[test]"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# train_X = feats[0:int(0.75*len(feats))]\n",
        "# test_X = feats[int(0.75*len(feats)):]\n",
        "\n",
        "# train_y = label_ids[0:int(0.75*len(label_ids))]\n",
        "# test_y = label_ids[int(0.75*len(label_ids)):]"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_X[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": [
              "array([  13,   82,   70, 2034,  284,   12,  135,   43,   29, 4993,  673,\n",
              "          6, 4993, 4357,  120,  781,  558,  202,  276,   74,  195, 1349,\n",
              "        195,  279,   82, 4993,   82,  548, 1143,   82, 1144, 2476,   70,\n",
              "        129,  282,  280,  281,    6, 2715,  306,   13,  281,  282,   48,\n",
              "       2106, 2107,   55,   58, 2108,   68, 2335,  767, 3746,   82, 2109,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def next_batch(X,y):\n",
        "    i = 0\n",
        "    n = len(X)\n",
        "    \n",
        "    while i <= n:\n",
        "        yield X[i:i+BATCH_SIZE], y[i:i+BATCH_SIZE]\n",
        "        i = i + BATCH_SIZE"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in next_batch([0,1,2,3,4,5,6], [0,1,2,1,1,1,1]):\n",
        "    print(x,y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "execution_count": 49,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.cuda()\n",
        "\n",
        "for epoch in range(100):\n",
        "    print(f\"==================================={epoch}================================\")\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    train_idx = 0\n",
        "\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    test_idx = 0\n",
        "\n",
        "#     scheduler.step(epoch)\n",
        "#     for sentence, label in list(zip(train_X, train_y)):\n",
        "    for sentence, label in next_batch(train_X, train_y):\n",
        "        if len(sentence) < BATCH_SIZE:\n",
        "            continue\n",
        "#         print(sentence, label)\n",
        "        model.zero_grad()\n",
        "\n",
        "        tag_scores = model(torch.LongTensor(sentence).view(BATCH_SIZE,150).cuda())\n",
        "        loss = loss_fn(tag_scores, torch.LongTensor(label).cuda())\n",
        "#         print(loss)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += (tag_scores.argmax(1) == torch.LongTensor(label).cuda()).sum().item()\n",
        "        train_idx += BATCH_SIZE\n",
        "        \n",
        "    print(train_loss / train_idx)\n",
        "    print(train_acc / train_idx)\n",
        "        \n",
        "    \n",
        "    for sentence, label in next_batch(test_X, test_y):\n",
        "        if len(sentence) < BATCH_SIZE:\n",
        "            continue\n",
        "#         text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            tag_scores = model(torch.LongTensor(sentence).view(BATCH_SIZE,150).cuda())\n",
        "\n",
        "            loss = loss_fn(tag_scores.view(BATCH_SIZE,-1), torch.LongTensor(label).cuda())\n",
        "            test_loss += loss.item()\n",
        "            \n",
        "            test_acc += (tag_scores.argmax(1) == torch.LongTensor(label).cuda()).sum().item()\n",
        "            test_idx += BATCH_SIZE\n",
        "\n",
        "    print(test_loss / test_idx)\n",
        "    print(test_acc/ test_idx)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================0================================\n",
            "0.16781754261599138\n",
            "0.5282451923076923\n",
            "0.1641502742740241\n",
            "0.5681818181818182\n",
            "===================================1================================\n",
            "0.1506988058009973\n",
            "0.7373798076923077\n",
            "0.16262866522778163\n",
            "0.6150568181818182\n",
            "===================================2================================\n",
            "0.14356621240194029\n",
            "0.8100961538461539\n",
            "0.16540299186652357\n",
            "0.5994318181818182\n",
            "===================================3================================\n",
            "0.1389083219692111\n",
            "0.8762019230769231\n",
            "0.16022068533030423\n",
            "0.625\n",
            "===================================4================================\n",
            "0.1342470356478141\n",
            "0.9146634615384616\n",
            "0.16159544309431856\n",
            "0.6349431818181818\n",
            "===================================5================================\n",
            "0.1316051329844273\n",
            "0.9459134615384616\n",
            "0.1608747819607908\n",
            "0.6292613636363636\n",
            "===================================6================================\n",
            "0.12875487125263765\n",
            "0.9573317307692307\n",
            "0.16590956327590076\n",
            "0.6150568181818182\n",
            "===================================7================================\n",
            "0.12625328924220341\n",
            "0.9723557692307693\n",
            "0.16391320797530087\n",
            "0.6420454545454546\n",
            "===================================8================================\n",
            "0.12598224328114435\n",
            "0.9765625\n",
            "0.16174954040483994\n",
            "0.671875\n",
            "===================================9================================\n",
            "0.12405660261328404\n",
            "0.9825721153846154\n",
            "0.16364179348403757\n",
            "0.671875\n",
            "===================================10================================\n",
            "0.12220779512650691\n",
            "0.9855769230769231\n",
            "0.1668678650801832\n",
            "0.6931818181818182\n",
            "===================================11================================\n",
            "0.12338299318574943\n",
            "0.9855769230769231\n",
            "0.165546502918005\n",
            "0.6761363636363636\n",
            "===================================12================================\n",
            "0.12190788941314587\n",
            "0.9873798076923077\n",
            "0.16387735645879398\n",
            "0.6846590909090909\n",
            "===================================13================================\n",
            "0.12125154742254661\n",
            "0.9885817307692307\n",
            "0.16196342997930266\n",
            "0.6860795454545454\n",
            "===================================14================================\n",
            "0.12074369493012245\n",
            "0.9933894230769231\n",
            "0.1614972579885613\n",
            "0.7102272727272727\n",
            "===================================15================================\n",
            "0.12050212733447552\n",
            "0.9933894230769231\n",
            "0.16164961355653676\n",
            "0.7059659090909091\n",
            "===================================16================================\n",
            "0.11981344595551491\n",
            "0.9921875\n",
            "0.16359758614139122\n",
            "0.6832386363636364\n",
            "===================================17================================\n",
            "0.1190628746811014\n",
            "0.9927884615384616\n",
            "0.16317201575095003\n",
            "0.6761363636363636\n",
            "===================================18================================\n",
            "0.11879137301674256\n",
            "0.9933894230769231\n",
            "0.16294972056692297\n",
            "0.6974431818181818\n",
            "===================================19================================\n",
            "0.11833221049836048\n",
            "0.9945913461538461\n",
            "0.1669164804572409\n",
            "0.7144886363636364\n",
            "===================================20================================\n",
            "0.11754809971898794\n",
            "0.9963942307692307\n",
            "0.16619637405330484\n",
            "0.7130681818181818\n",
            "===================================21================================\n",
            "0.11750738831380239\n",
            "0.9951923076923077\n",
            "0.16355736723000353\n",
            "0.7130681818181818\n",
            "===================================22================================\n",
            "0.11702232091472699\n",
            "0.9957932692307693\n",
            "0.1609061106362126\n",
            "0.734375\n",
            "===================================23================================\n",
            "0.11707119643688202\n",
            "0.9951923076923077\n",
            "0.16441098228096962\n",
            "0.7315340909090909\n",
            "===================================24================================\n",
            "0.11655349377542734\n",
            "0.9957932692307693\n",
            "0.16256813806566325\n",
            "0.7414772727272727\n",
            "===================================25================================\n",
            "0.11670963695416084\n",
            "0.9951923076923077\n",
            "0.16647905179045416\n",
            "0.7116477272727273\n",
            "===================================26================================\n",
            "0.11621110735890958\n",
            "0.9951923076923077\n",
            "0.15873787823048505\n",
            "0.7244318181818182\n",
            "===================================27================================\n",
            "0.11562202104295675\n",
            "0.9969951923076923\n",
            "0.16374724290587686\n",
            "0.7301136363636364\n",
            "===================================28================================\n",
            "0.11541361118165347\n",
            "0.9975961538461539\n",
            "0.16202205995267088\n",
            "0.7514204545454546\n",
            "===================================29================================\n",
            "0.11537728129098049\n",
            "0.9957932692307693\n",
            "0.1668293330479752\n",
            "0.7315340909090909\n",
            "===================================30================================\n",
            "0.1155817684932397\n",
            "0.9951923076923077\n",
            "0.16891130059957504\n",
            "0.7428977272727273\n",
            "===================================31================================\n",
            "0.11528658573157512\n",
            "0.9927884615384616\n",
            "0.16209564595059914\n",
            "0.7301136363636364\n",
            "===================================32================================\n",
            "0.11482161570053834\n",
            "0.9945913461538461\n",
            "0.16624352166598494\n",
            "0.7485795454545454\n",
            "===================================33================================\n",
            "0.1142726824260675\n",
            "0.9963942307692307\n",
            "0.16339294239878654\n",
            "0.7514204545454546\n",
            "===================================34================================\n",
            "0.11416642754696883\n",
            "0.9963942307692307\n",
            "0.16095805642279712\n",
            "0.75\n",
            "===================================35================================\n",
            "0.11436517257243395\n",
            "0.9963942307692307\n",
            "0.1627349592745304\n",
            "0.75\n",
            "===================================36================================\n",
            "0.11379716767428014\n",
            "0.9957932692307693\n",
            "0.16892675547437233\n",
            "0.7443181818181818\n",
            "===================================37================================\n",
            "0.11353637621952938\n",
            "0.9957932692307693\n",
            "0.1741894358261065\n",
            "0.7215909090909091\n",
            "===================================38================================\n",
            "0.11381686228112532\n",
            "0.9957932692307693\n",
            "0.17451030388474464\n",
            "0.7329545454545454\n",
            "===================================39================================\n",
            "0.11372829765941088\n",
            "0.9951923076923077\n",
            "0.1714778786355799\n",
            "0.7286931818181818\n",
            "===================================40================================\n",
            "0.11351220617787196\n",
            "0.9951923076923077\n",
            "0.17634406651962886\n",
            "0.7372159090909091\n",
            "===================================41================================\n",
            "0.11304588752010694\n",
            "0.9963942307692307\n",
            "0.17150435528971933\n",
            "0.7315340909090909\n",
            "===================================42================================\n",
            "0.11315581381607515\n",
            "0.9951923076923077\n",
            "0.18155615404248238\n",
            "0.7230113636363636\n",
            "===================================43================================\n",
            "0.112841514727244\n",
            "0.9957932692307693\n",
            "0.17658813399347392\n",
            "0.7116477272727273\n",
            "===================================44================================\n",
            "0.11366935554318704\n",
            "0.9951923076923077\n",
            "0.1828143550929698\n",
            "0.7357954545454546\n",
            "===================================45================================\n",
            "0.11276911843854648\n",
            "0.9969951923076923\n",
            "0.1793282895602963\n",
            "0.75\n",
            "===================================46================================\n",
            "0.11280827331714906\n",
            "0.9951923076923077\n",
            "0.1845487765967846\n",
            "0.7301136363636364\n",
            "===================================47================================\n",
            "0.11414848676381203\n",
            "0.9903846153846154\n",
            "0.17288267341527072\n",
            "0.7514204545454546\n",
            "===================================48================================\n",
            "0.11355786011196099\n",
            "0.9951923076923077\n",
            "0.172729195010933\n",
            "0.7301136363636364\n",
            "===================================49================================\n",
            "0.11235390001764664\n",
            "0.9969951923076923\n",
            "0.18780116736888885\n",
            "0.7428977272727273\n",
            "===================================50================================\n",
            "0.11190899275243282\n",
            "0.9975961538461539\n",
            "0.19034895673394203\n",
            "0.7357954545454546\n",
            "===================================51================================\n",
            "0.11202405894605014\n",
            "0.9951923076923077\n",
            "0.18826204233548857\n",
            "0.6846590909090909\n",
            "===================================52================================\n",
            "0.11241800638918693\n",
            "0.9957932692307693\n",
            "0.19356294450434772\n",
            "0.71875\n",
            "===================================53================================\n",
            "0.11224006911596426\n",
            "0.9963942307692307\n",
            "0.1904169429432262\n",
            "0.7357954545454546\n",
            "===================================54================================\n",
            "0.11173851157610233\n",
            "0.9963942307692307\n",
            "0.18770087882876396\n",
            "0.7286931818181818\n",
            "===================================55================================\n",
            "0.11167095716183002\n",
            "0.9975961538461539\n",
            "0.1999517059461637\n",
            "0.7457386363636364\n",
            "===================================56================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-a3670bdbcd29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 50,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "sklearn.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": [
              "'0.19.1'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 54,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = []\n",
        "y_true = []\n",
        "for sentence, label in next_batch(test_X, test_y):\n",
        "        if len(sentence) < BATCH_SIZE:\n",
        "            continue\n",
        "#         text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            tag_scores = model(torch.LongTensor(sentence).view(BATCH_SIZE,150).cuda())\n",
        "            print(\"***********\")\n",
        "#             print(tag_scores.shape)\n",
        "#             print(tag_scores.view(BATCH_SIZE,-1).shape)\n",
        "            loss = loss_fn(tag_scores, torch.LongTensor(label).cuda())\n",
        "            test_loss += loss.item()\n",
        "            \n",
        "#             print(tag_scores.shape)\n",
        "            print(tag_scores.argmax(1))\n",
        "            print(label)\n",
        "            \n",
        "            y_preds.append(tag_scores.argmax(1).cpu().numpy())\n",
        "            y_true.append(label)\n",
        "            test_acc += (tag_scores.argmax(1) == torch.LongTensor(label).cuda()).sum().item()\n",
        "            test_idx += BATCH_SIZE\n",
        "            \n",
        "            print(test_acc/ test_idx)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array(y_true).flatten()"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.array(y_preds).flatten()"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_preds, target_names=[\"bad\", \"neutral\", \"good\"]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        bad       0.77      0.81      0.79       320\n",
            "    neutral       0.73      0.76      0.74       217\n",
            "       good       0.67      0.57      0.62       167\n",
            "\n",
            "avg / total       0.73      0.74      0.73       704\n",
            "\n"
          ]
        }
      ],
      "execution_count": 72,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_true, y_preds)\n"
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cnf_matrix, classes=[\"bad\", \"neutral\", \"good\"],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[259  36  25]\n",
            " [ 31 164  22]\n",
            " [ 47  24  96]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": [
              "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\n"
            ],
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 84,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "nteract": {
      "version": "0.21.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}